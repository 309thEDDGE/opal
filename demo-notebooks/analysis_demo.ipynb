{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264d3ae8-5bf8-48d1-8367-20c06e4bcbaa",
   "metadata": {},
   "source": [
    "# Modern Data Analytics Tools on an Air-Gapped Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4977d-c9fd-4320-a54d-55b2eea34af0",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- How can I use modern data analytics tooling, such as Numpy, Matplotlib, and even PyTorch on an air-gapped network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c7275-c621-4c86-b015-9b0f76bcb606",
   "metadata": {},
   "source": [
    "### Example Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66443802-44d6-481a-b12b-a7cfefe0d47f",
   "metadata": {},
   "source": [
    "#### Imports/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcd5676-820d-4cf3-aa65-55d406af723b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dask.distributed import Client, progress\n",
    "import dask.bag\n",
    "import dask.dataframe\n",
    "import metaflow\n",
    "from IPython.display import Video\n",
    "import yaml\n",
    "\n",
    "import opal.flow\n",
    "from opal.weave.create_index import create_index_from_s3\n",
    "\n",
    "s3 = opal.flow.minio_s3fs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1d60b-53f6-4a21-9fb4-6dfac20a1c6e",
   "metadata": {},
   "source": [
    "#### Gather References to Uploaded Data\n",
    "- Use OPAL's Weave package to access metadata from over 500 Chapter 10s stored on AWS S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600f6723-e25d-4e47-9a85-d374151b2396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "The Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/s3fs/core.py:683\u001b[0m, in \u001b[0;36mS3FileSystem._lsdir\u001b[0;34m(self, path, refresh, max_items, delimiter, prefix, versions)\u001b[0m\n\u001b[1;32m    682\u001b[0m files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 683\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterdir(\n\u001b[1;32m    684\u001b[0m     bucket,\n\u001b[1;32m    685\u001b[0m     max_items\u001b[38;5;241m=\u001b[39mmax_items,\n\u001b[1;32m    686\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    687\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[1;32m    688\u001b[0m     versions\u001b[38;5;241m=\u001b[39mversions,\n\u001b[1;32m    689\u001b[0m ):\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/s3fs/core.py:733\u001b[0m, in \u001b[0;36mS3FileSystem._iterdir\u001b[0;34m(self, bucket, max_items, delimiter, prefix, versions)\u001b[0m\n\u001b[1;32m    726\u001b[0m it \u001b[38;5;241m=\u001b[39m pag\u001b[38;5;241m.\u001b[39mpaginate(\n\u001b[1;32m    727\u001b[0m     Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m    728\u001b[0m     Prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[1;32m    732\u001b[0m )\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m i\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommonPrefixes\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/aiobotocore/paginate.py:30\u001b[0m, in \u001b[0;36mAioPageIterator.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(current_kwargs)\n\u001b[1;32m     31\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_parsed_response(response)\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/aiobotocore/client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    357\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the ListObjectsV2 operation: The Access Key Id you provided does not exist in our records.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_index_from_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbasket-data-with-arinc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresources/schema.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/opal/weave/create_index.py:60\u001b[0m, in \u001b[0;36mcreate_index_from_s3\u001b[0;34m(root_dir, schema_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema_path\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a string: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m opal_s3fs \u001b[38;5;241m=\u001b[39m opal\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mminio_s3fs()\n\u001b[0;32m---> 60\u001b[0m basket_jsons \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mopal_s3fs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasket_manifest.json\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     62\u001b[0m index_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(schema_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/fsspec/asyn.py:114\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/fsspec/asyn.py:99\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/fsspec/asyn.py:54\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/s3fs/core.py:802\u001b[0m, in \u001b[0;36mS3FileSystem._find\u001b[0;34m(self, path, maxdepth, withdirs, detail, prefix)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_find(\n\u001b[1;32m    791\u001b[0m         bucket \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m key, maxdepth\u001b[38;5;241m=\u001b[39mmaxdepth, withdirs\u001b[38;5;241m=\u001b[39mwithdirs, detail\u001b[38;5;241m=\u001b[39mdetail\n\u001b[1;32m    792\u001b[0m     )\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# TODO: implement find from dircache, if all listings are present\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# if refresh is False:\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m#     out = incomplete_tree_dirs(self.dircache, path)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m#         return super().find(path)\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m#     # else: we refresh anyway, having at least two missing trees\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lsdir(path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, prefix\u001b[38;5;241m=\u001b[39mprefix)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out \u001b[38;5;129;01mand\u001b[39;00m key:\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/singleuser/lib/python3.10/site-packages/s3fs/core.py:696\u001b[0m, in \u001b[0;36mS3FileSystem._lsdir\u001b[0;34m(self, path, refresh, max_items, delimiter, prefix, versions)\u001b[0m\n\u001b[1;32m    694\u001b[0m     files \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dirs\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m translate_boto_error(e)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;129;01mand\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m versions:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdircache[path] \u001b[38;5;241m=\u001b[39m files\n",
      "\u001b[0;31mPermissionError\u001b[0m: The Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "index = create_index_from_s3('basket-data-with-arinc', 'resources/schema.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44279ec9-9f96-48f3-842c-36669019ef50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use index to access and sort all of the information we need\n",
    "def get_all_uuids_of_specific_type(index, basket_type):\n",
    "    return index[index[\"basket_type\"] == basket_type][\"uuid\"].tolist()\n",
    "def get_first_gen_children(parsed_ch10_uuid, index):\n",
    "    return index[\n",
    "        [(parsed_ch10_uuid in puuid) for puuid in index[\"parent_uuids\"]]\n",
    "    ]\n",
    "def get_address_of_specific_type(parsed_ch10_uuid, index, basket_type):\n",
    "    first_gen_children = get_first_gen_children(parsed_ch10_uuid, index)\n",
    "    index_subset = first_gen_children[\n",
    "        first_gen_children[\"basket_type\"] == basket_type\n",
    "    ]\n",
    "    if len(index_subset) != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"There is not exactly one {basket_type} \"\n",
    "            f\"child basket for UUID: {parsed_ch10_uuid}\"\n",
    "        )\n",
    "    return index_subset[\"address\"].iloc[0]\n",
    "parsed_ch10_uuids = get_all_uuids_of_specific_type(\n",
    "    index=index, basket_type=\"ch10_parsed\"\n",
    ")\n",
    "def get_hud_video(index):\n",
    "    return index[index[\"basket_type\"] == \"HUD_video\"][\"address\"].tolist()[0]\n",
    "\n",
    "arinc_and_1553_addresses = [\n",
    "    {\n",
    "        \"MILSTD1553\": get_address_of_specific_type(\n",
    "            uuid, index, \"ch10_translated_MILSTD1553\"\n",
    "        ),\n",
    "        \"ARINC429\": get_address_of_specific_type(\n",
    "            uuid, index, \"ch10_translated_ARINC429\"\n",
    "        )\n",
    "    }\n",
    "    for uuid in parsed_ch10_uuids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0881373-4b68-467b-a3cf-e72d27a339b0",
   "metadata": {},
   "source": [
    "### Single Flight Analysis\n",
    "#### Find and plot cruising altitude across one flight\n",
    "- Utilize Pandas and Numpy libraries to quickly and efficiently subset and transform data.\n",
    "- Utilize Matplotlib to easily create an informative plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d378fd5-1caf-4bbf-93e4-a682672f94ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\":18})\n",
    "altitude = \"NAV-25\"\n",
    "altitude_valid = \"NAV-0111\"\n",
    "rpm = \"N1_RPM_ACTUAL\"\n",
    "rpm_dataset = \"Engine_Fan_RPM_N1_ACTUAL_40\"\n",
    "\n",
    "def plot_cruise_altitude(t_1553):\n",
    "    # Get the 1553 data\n",
    "    original_df = pd.read_parquet(t_1553, filesystem=s3)\n",
    "    original_df[\"time\"] = (\n",
    "        original_df[\"time\"] - original_df[\"time\"].iloc[0]\n",
    "    ) / 10**9 / 60\n",
    "    df_1553 = original_df\n",
    "    \n",
    "    # Filter 1553 by the 'altitude valid'\n",
    "    df_1553 = df_1553[df_1553[altitude_valid]]\n",
    "    df_1553 = df_1553.dropna()\n",
    "    \n",
    "    # Calculate change in altitude over time (time is in nanoseconds)\n",
    "    df_1553.loc[:,\"diff_altitude\"] = (\n",
    "        df_1553[altitude].diff() / (df_1553[\"time\"].diff() / 10**9)\n",
    "    )\n",
    "    # Smooth out the altitude derivative\n",
    "    df_1553.loc[:,\"diff_altitude\"] = (\n",
    "        df_1553[\"diff_altitude\"].rolling(int(1 / 0.04)).mean()\n",
    "    )\n",
    "    \n",
    "    # Select only where altitude rate of change is small enough (< 0.25 ft/sec.)\n",
    "    # and the aircraft is sufficiently above what we think is ground level\n",
    "    start_altitude = df_1553[altitude].iloc[:10].mean()\n",
    "    end_altitude = df_1553[altitude].iloc[-10:].mean()\n",
    "    min_altitude = max(start_altitude, end_altitude)\n",
    "    df_1553 = df_1553[abs(df_1553[\"diff_altitude\"]) < 0.25]\n",
    "    df_1553 = df_1553[df_1553[altitude] > min_altitude * 2]\n",
    "    df_1553 = df_1553.dropna()\n",
    "    \n",
    "    # Create the plots\n",
    "    ax = df_1553.plot(kind=\"scatter\", x=\"time\", y=altitude,\n",
    "                      c=\"tab:orange\", label=\"Cruise Altitude (ft)\",\n",
    "                      figsize=(13,7))\n",
    "    original_df.plot(kind=\"scatter\", x='time', y=altitude,\n",
    "                     ax=ax, label=\"General Altitude (ft)\", s=1)\n",
    "    ax.set_ylabel(\"Altitude (ft)\")\n",
    "    ax.set_xlabel(\"Time (min)\")\n",
    "\n",
    "# basket = translated_index[translated_index.label == '652200101100441'].iloc[0]\n",
    "basket = index[\n",
    "    np.array(index[\"label\"] == '652200101100441') &\n",
    "    np.array(index[\"basket_type\"] == \"ch10_translated_MILSTD1553\")\n",
    "]\n",
    "nav_path = os.path.join(basket['address'].iloc[0],\n",
    "                        'parsed_data_translated', 'NAV.parquet', '00.parquet')\n",
    "plot_cruise_altitude(nav_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f425c-35b1-45bf-8812-da5549fe0464",
   "metadata": {},
   "source": [
    "### Multi-flight Analysis\n",
    "#### Utilize available modern analytics tooling to process 500+ Chapter 10s in tandem\n",
    "- Dask libraries enable multiprocessing\n",
    "- OPAL can process all of these Chapter 10s in well under one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fe1dc-6535-47c8-b3cc-1abd5391bef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rpm_at_cruise_altitude(t_1553, t_429):\n",
    "    # get the 1553 and ARINC429 data\n",
    "    t_1553 = os.path.join(t_1553, 'parsed_data_translated',\n",
    "                          'NAV.parquet', '00.parquet')\n",
    "    t_429 = os.path.join(t_429,'parsed_data_translated',\n",
    "                         f'{rpm_dataset}.parquet', '00.parquet')\n",
    "    df_1553 = pd.read_parquet(t_1553, filesystem=s3)\n",
    "    df_429 = pd.read_parquet(t_429, filesystem=s3)\n",
    "    \n",
    "    # filter 1553 by the 'altitude valid' bit\n",
    "    df_1553 = df_1553[df_1553[altitude_valid]]\n",
    "    \n",
    "    # join 1553 and ARINC429 data by time\n",
    "    joined = pd.concat([ df_1553, df_429 ]).sort_values(\"time\")\n",
    "    joined[rpm] = joined[rpm].fillna(method=\"ffill\")\n",
    "    joined = joined.dropna().copy()\n",
    "    \n",
    "    # calculate change in altitude over time (time is in nanoseconds)\n",
    "    joined.loc[:,\"diff_altitude\"] = (\n",
    "        joined[altitude].diff() / (joined[\"time\"].diff() / 10**9)\n",
    "    )\n",
    "    # smooth out the altitude derivative\n",
    "    joined.loc[:,\"diff_altitude\"] = (\n",
    "        joined[\"diff_altitude\"].rolling(int(1 / 0.04)).mean()\n",
    "    )\n",
    "    \n",
    "    # select only where difference in altitude is small enough\n",
    "    # and the aircraft is sufficiently above what we think is ground level\n",
    "    start_altitude = joined[altitude].iloc[:10].mean()\n",
    "    end_altitude = joined[altitude].iloc[-10:].mean()\n",
    "    min_altitude = max(start_altitude, end_altitude)\n",
    "    joined = joined[abs(joined[\"diff_altitude\"]) < 0.25]\n",
    "    joined = joined[joined[altitude] > min_altitude * 2]\n",
    "    joined = joined.dropna()\n",
    "    \n",
    "    # group periods of time when the jet was cruising, take the average\n",
    "    joined['group'] = (joined['time'].diff() > 60 * 10**9).cumsum()\n",
    "    grouped = joined.groupby('group').mean(numeric_only=True)\n",
    "    return grouped\n",
    "\n",
    "with Client(n_workers=16, processes=True) as client:  \n",
    "    dashboard_port = client.cluster.dashboard_link.split(':')[-1].split('/')[0]\n",
    "    dashboard_link = (\n",
    "        f\"https://opal.opalacceptance.dso.mil\"\n",
    "        f\"{os.environ['JUPYTERHUB_SERVICE_PREFIX']}\"\n",
    "        f\"proxy/{dashboard_port}/status\"\n",
    "    )\n",
    "    display(dashboard_link)\n",
    "    # ds_bag = dask.bag.from_sequence(translated_index.iloc)\n",
    "    ds_bag = dask.bag.from_sequence(arinc_and_1553_addresses)\n",
    "    \n",
    "    analysis_count = ds_bag.count().compute()\n",
    "    ds_bag = ds_bag.map(\n",
    "        lambda address_tuple: get_rpm_at_cruise_altitude(\n",
    "            address_tuple['MILSTD1553'], address_tuple['ARINC429']\n",
    "        )\n",
    "    )\n",
    "    future = client.compute(ds_bag)\n",
    "    progress(future, notebook=False)\n",
    "    df = pd.concat(future.result())\n",
    "\n",
    "print(f' Datasets Analyzed = {analysis_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1dd53-1d1b-4223-ab72-dee039dea191",
   "metadata": {},
   "source": [
    "#### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cac8a2-e1bf-4fff-97ce-e0b1892fbdf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.plot(\n",
    "    kind=\"scatter\", x=altitude, y=rpm, \n",
    "    xlabel=\"Cruise Altitude (ft)\", ylabel=\"Engine Turbine Speed (Percent Max.)\",\n",
    "    title=\"Turbine Speed at Cruise Altitude (all flights)\",\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55e186-fc85-442a-ab4c-98daac356e06",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Investigate potential correlations between turbine speed and cruise altitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacd0ef-c2bb-41b6-a7a2-21e7fa767e0f",
   "metadata": {},
   "source": [
    "#### Fit the Data to a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a8d75-cc45-42ff-b1fd-ce6ed46b706e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turbine_speed = np.array(df['NAV-25']).reshape(-1,1)\n",
    "X = df.drop(columns = ['time', 'N1_RPM_ACTUAL', 'diff_altitude'])\n",
    "y = df['N1_RPM_ACTUAL']\n",
    "all_columns_reg = LinearRegression().fit(X, y)\n",
    "turbine_speed_reg = LinearRegression().fit(turbine_speed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cd375-0349-4606-80a0-b4bbfd666b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Turbine Speed at Cruise Altitude\")\n",
    "plt.scatter(X['NAV-25'], y)\n",
    "plt.scatter(X['NAV-25'].sort_values(),\n",
    "            all_columns_reg.predict(X.sort_values('NAV-25')),\n",
    "            marker = '.', c = 'r',\n",
    "            label='All Features Regression', linewidth = .5)\n",
    "plt.plot(turbine_speed, turbine_speed_reg.predict(turbine_speed),\n",
    "         color='g', label='Turbine Speed Regression', linewidth = 3)\n",
    "\n",
    "plt.xlabel(\"Cruise Altitude (ft)\")\n",
    "plt.ylabel (\"Engine Turbine Speed (Percent Max.)\")\n",
    "plt.ylim(top=100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec908d13-e71f-4125-8480-9b0bfe1ca241",
   "metadata": {},
   "source": [
    "#### R<sup>2</sup> Score for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a547c-3676-4278-bb1f-aff5e846a9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('All Features Regression score: ', all_columns_reg.score(X, y))\n",
    "print('Turbine Speed Regression score: ', turbine_speed_reg.score(turbine_speed, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e6f14-e0d3-4ce4-9932-cd2a6dde1031",
   "metadata": {},
   "source": [
    "#### Calculate Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefcd8f-8561-44b2-8db6-488c43ef5d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "address = index[index.basket_type == 'NASA_MILSTD1553_DTS'].address.iloc[0]\n",
    "with s3.open(os.path.join(address, 'NASA_MILSTD1553_DTS.yaml')) as file:\n",
    "    dts_1553 = yaml.safe_load(file)\n",
    "translation = {}\n",
    "for key in dts_1553['translatable_message_definitions'][\n",
    "    'NAV'\n",
    "]['word_elem'].keys():\n",
    "    translation[key] = dts_1553['translatable_message_definitions']['NAV'][\n",
    "        'word_elem'\n",
    "    ][key]['desc']\n",
    "\n",
    "cors_with_target = X.rename(columns = translation).corrwith(y)\n",
    "cors_with_target.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c71b92-5443-4818-a2c4-18308dff70b4",
   "metadata": {},
   "source": [
    "#### OPAL can handle video, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942927d-07aa-433d-9202-b03a1a46cfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.download(os.path.join(get_hud_video(index), \"Video.mov\"), \"Video.mov\")\n",
    "Video(\"Video.mov\", width=480*1.4, height=316*1.4,\n",
    "      html_attributes=\"controls muted loop autoplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea8caac-d20e-4a8a-945d-6ec44b12c476",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### - OPAL allows the creation of any data based analysis, much like a word processor application allows the creation of any text document.\n",
    "### - OPAL enables modern open source analytics toolsets to exist on air-gapped networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:singleuser] *",
   "language": "python",
   "name": "conda-env-singleuser-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
